name: SEC Filing Analysis Pipeline

on:
  # Run 4 times daily at 6-hour intervals
  schedule:
    - cron: '0 0,6,12,18 * * *'  # 12am, 6am, 12pm, 6pm UTC

  # Allow manual triggering
  workflow_dispatch:
    inputs:
      phase:
        description: 'Pipeline phase to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - fetch
          - analyze
          - generate
          - publish

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r pipeline/requirements.txt

      - name: Run pipeline
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_BEDROCK_MODEL_ID: ${{ secrets.AWS_BEDROCK_MODEL_ID }}
          S3_BUCKET_FILINGS: ${{ secrets.S3_BUCKET_FILINGS }}
          S3_BUCKET_AUDIO: ${{ secrets.S3_BUCKET_AUDIO }}
          CONTACT_EMAIL: ${{ secrets.CONTACT_EMAIL }}
        run: |
          PHASE="${{ github.event.inputs.phase || 'all' }}"
          echo "Running pipeline phase: $PHASE"
          python3 pipeline/main.py --phase $PHASE

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_number }}
          path: |
            *.log
            /tmp/*.log
          retention-days: 7
